{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/rag_from_scratch/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\") # Fazer o embedding usando esse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"/home/patrick/rag_from_scratch/AI_Information.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\" # Initizalizing an empty string to store the extarcted text\n",
    "\n",
    "    # Iterating through each page in the pdf\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]\n",
    "        text = page.get_text(\"text\")\n",
    "        all_text += text\n",
    "\n",
    "    return all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, n, overlap):\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(0, len(text), n - overlap):\n",
    "        chunks.append(text[i:i+n])\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = chunk_text(extracted_text, 1000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 38\n",
      "\n",
      "First text chunk:\n",
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
      "the project of developing systems endowed with the intellectual processes characteristic of \n",
      "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
      "experience. Over the past few decades, advancements in computing power and data availability \n",
      "have significantly accelerated the development and deployment of AI. \n",
      "Historical Context \n",
      "The idea of artificial intelligence has existed for centuries, often depicted in myths and fiction. \n",
      "However, the formal field of AI research began in the mid-20th century. The Dartmouth Workshop \n",
      "in 1956 is widely considered the birthplace of AI. Early AI research focused on problem-solving \n",
      "and symbolic methods. The 1980s saw a rise in exp\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Number of text chunks:\", len(text_chunks))\n",
    "\n",
    "print(\"\\nFirst text chunk:\")\n",
    "print(text_chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text):\n",
    "    response = embedder.encode(text)\n",
    "    return response\n",
    "\n",
    "response = create_embeddings(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, text_chunks, embeddings, k=5, context_size=2):\n",
    "    query_embedding = create_embeddings(query)\n",
    "    similarity_scores = []\n",
    "\n",
    "    for i, chunk_embedding in enumerate(embeddings):\n",
    "        similarity_score = cosine_similarity(np.array(query_embedding), np.array(chunk_embedding))\n",
    "        similarity_scores.append((i, similarity_score))\n",
    "\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_index = similarity_scores[0][0]\n",
    "    start = max(0, top_index - context_size)\n",
    "    end = min(len(text_chunks), top_index + context_size + 1)\n",
    "\n",
    "    # Return the relevant chunk along with its neighboring context chunks\n",
    "    return [text_chunks[i] for i in range(start, end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is 'Explainable AI' and why is it considered important?\n",
      "Context 1:\n",
      "\n",
      "privacy and human rights. \n",
      "Public Perception and Trust \n",
      "Public perception and trust in AI are essential for its widespread adoption and positive social \n",
      "impact. Building trust requires transparency, explainability, and responsible development and \n",
      "deployment of AI systems. \n",
      "Global Collaboration \n",
      "Addressing the social impact of AI requires global collaboration and cooperation. This includes \n",
      "sharing knowledge, developing standards, and promoting responsible AI practices across \n",
      "borders. \n",
      "Chapter 14: AI and Smart Cities \n",
      "Urban Planning and Management \n",
      "AI enhances urban planning and management by analyzing data, optimizing resource allocation, \n",
      "and improving city services. AI-powered systems support sustainable urban development, \n",
      "enhance quality of life, and promote efficient city operations. \n",
      "Smart Transportation \n",
      "AI-powered smart transportation systems optimize traffic flow, reduce congestion, and enhance \n",
      "public transit. These systems use real-time data to manage traffic signals, pro\n",
      "=====================================\n",
      "Context 2:\n",
      "estion, and enhance \n",
      "public transit. These systems use real-time data to manage traffic signals, provide route \n",
      "recommendations, and support autonomous vehicles. \n",
      "Energy Management \n",
      "AI optimizes energy management in smart cities by predicting demand, managing supply, and \n",
      "promoting energy efficiency. AI-powered systems enhance grid stability, reduce energy waste, \n",
      "and support the integration of renewable energy sources. \n",
      "Public Safety and Security \n",
      "AI enhances public safety and security in smart cities by monitoring public spaces, detecting \n",
      "anomalies, and supporting emergency response. AI-powered systems improve crime prevention, \n",
      "enhance situational awareness, and support rapid response to incidents. \n",
      "Environmental Monitoring \n",
      "AI-powered environmental monitoring systems track air and water quality, detect pollution, and \n",
      "support environmental protection efforts. These systems provide real-time data, identify \n",
      "pollution sources, and inform environmental policies. \n",
      "Chapter 15: The Futu\n",
      "=====================================\n",
      "Context 3:\n",
      "eal-time data, identify \n",
      "pollution sources, and inform environmental policies. \n",
      "Chapter 15: The Future of AI Research \n",
      "Advancements in Deep Learning \n",
      "Continued advancements in deep learning are expected to drive further breakthroughs in AI. \n",
      "Research is focused on developing more efficient and interpretable deep learning models, as well \n",
      "as exploring new architectures and training techniques. \n",
      "Explainable AI (XAI) \n",
      "Explainable AI (XAI) aims to make AI systems more transparent and understandable. Research in \n",
      "XAI focuses on developing methods for explaining AI decisions, enhancing trust, and improving \n",
      "accountability. \n",
      "AI and Neuroscience \n",
      "The intersection of AI and neuroscience is a promising area of research. Understanding the \n",
      "human brain can inspire new AI algorithms and architectures, while AI can provide insights into \n",
      "brain function and cognition. \n",
      "AI Safety and Security \n",
      "Ensuring the safety and security of AI systems is a critical area of research. This includes \n",
      "developing meth\n",
      "=====================================\n",
      "Context 4:\n",
      "the safety and security of AI systems is a critical area of research. This includes \n",
      "developing methods for verifying AI behavior, mitigating risks, and preventing unintended \n",
      "consequences. \n",
      "Human-Centered AI \n",
      "Human-centered AI focuses on developing AI systems that are aligned with human values, \n",
      "enhance human capabilities, and promote well-being. This involves considering ethical, social, \n",
      "and psychological aspects of AI development and deployment. \n",
      " \n",
      " \n",
      "Chapter 16: AI and the Arts \n",
      "Generative AI and Creativity \n",
      "Generative AI models, such as Generative Adversarial Networks (GANs) and transformers, are \n",
      "capable of creating original content, including images, text, and music. These models are pushing \n",
      "the boundaries of AI-driven creativity and opening up new possibilities for artistic expression. \n",
      "AI as a Collaborative Partner \n",
      "AI is increasingly used as a collaborative partner for artists and designers. AI tools can assist with \n",
      "tasks such as ideation, prototyping, and refinement, enhan\n",
      "=====================================\n",
      "Context 5:\n",
      " and designers. AI tools can assist with \n",
      "tasks such as ideation, prototyping, and refinement, enhancing the creative process and \n",
      "enabling new forms of expression. \n",
      "AI in Music and Sound Design \n",
      "AI is transforming music and sound design by enabling new forms of composition, performance, \n",
      "and production. AI-powered tools can generate melodies, harmonies, and rhythms, create \n",
      "interactive musical experiences, and assist with audio mixing and mastering. \n",
      "AI in Visual Arts and Design \n",
      "AI is used in visual arts and design to generate images, create animations, and assist with design \n",
      "processes. AI-powered tools can create realistic images, generate design variations, and \n",
      "automate repetitive tasks, freeing up artists to focus on creative exploration. \n",
      "AI and Interactive Media \n",
      "AI is enhancing interactive media, such as video games and virtual reality experiences, by \n",
      "enabling more realistic and engaging interactions. AI-powered characters, dynamic \n",
      "environments, and personalized content cre\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "with open('val.json') as f:\n",
    "    data = json.load(f)\n",
    "query = data[0]['question']\n",
    "\n",
    "top_chunks = semantic_search(query, text_chunks, response, k=2)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "\n",
    "for i, chunk in enumerate(top_chunks):\n",
    "    print(f\"Context {i + 1}:\\n{chunk}\\n=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: 'I do not have enough information to answer that.'\"\n",
    "\n",
    "def generate_response(system_prompt, user_message, model=\"gpt-3.5-turbo-1106\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "user_prompt = \"\\n\".join([f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\" for i, chunk in enumerate(top_chunks)])\n",
    "user_prompt = f\"{user_prompt}\\nQuestion: {query}\"\n",
    "\n",
    "ai_response = generate_response(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Explainable AI (XAI) aims to make AI systems more transparent and understandable. Research in XAI focuses on developing methods for explaining AI decisions, enhancing trust, and improving accountability. It is considered important because it contributes to building trust in AI systems, which is essential for their widespread adoption and positive social impact.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AI response is very close to the true response, capturing the essence of Explainable AI (XAI) and its importance in building trust, enhancing accountability, and ensuring fairness in AI systems. Therefore, the score is 1.\n"
     ]
    }
   ],
   "source": [
    "evaluate_system_prompt = \"You are an intelligent evaluation system tasked with assessing the AI assistant's responses. If the AI assistant's response is very close to the true response, assign a score of 1. If the response is incorrect or unsatisfactory in relation to the true response, assign a score of 0. If the response is partially aligned with the true response, assign a score of 0.5.\"\n",
    "\n",
    "evaluation_prompt = f\"User Query: {query}\\nAI Response:\\n{ai_response.choices[0].message.content}\\nTrue Response: {data[0]['ideal_answer']}\\n{evaluate_system_prompt}\"\n",
    "\n",
    "evaluation_response = generate_response(evaluate_system_prompt, evaluation_prompt)\n",
    "\n",
    "print(evaluation_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "\n",
    "# Initialize the SentenceTransformer model and set the similarity function\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "model.similarity_fn_name = SimilarityFunction.DOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_validation_data(k):\n",
    "    system_prompt = \"\"\"You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly and exactly from the provided context, respond with: 'I do not have enough information to answer that.'\n",
    "    First think about the keywords from the question and then use them to elaborate the answer.\n",
    "    The response needs to be just the answer sentence\n",
    "    \n",
    "    \"\"\"\n",
    "    # Load the validation data from the JSON file\n",
    "    with open('val.json') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # List to store the results for each sample\n",
    "    results = []\n",
    "\n",
    "    # Iterate over each example in the validation data\n",
    "    for idx, item in enumerate(data):\n",
    "        query = item['question']\n",
    "        ideal_answer = item['ideal_answer']\n",
    "        \n",
    "        # Retrieve the top k most relevant context chunks\n",
    "        top_chunks = semantic_search(query, text_chunks, response, k=k)\n",
    "        \n",
    "        # Create the user prompt by combining all context chunks and the query\n",
    "        context_prompt = \"\\n\".join([\n",
    "            f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\"\n",
    "            for i, chunk in enumerate(top_chunks)\n",
    "        ])\n",
    "        user_prompt = f\"{context_prompt}\\nQuestion: {query}\"\n",
    "        \n",
    "        # Generate the AI response using the system prompt and the user prompt\n",
    "        ai_response = generate_response(system_prompt, user_prompt).choices[0].message.content\n",
    "        \n",
    "        # Evaluate similarity using SentenceTransformer\n",
    "        # Encode the AI response and ideal answer\n",
    "        embedding_response = model.encode([ai_response])\n",
    "        embedding_ideal = model.encode([ideal_answer])\n",
    "        # Compute similarity score (result is a 1x1 matrix; extract the single value)\n",
    "        similarity_matrix = model.similarity(embedding_response, embedding_ideal)\n",
    "        score = similarity_matrix[0][0].numpy()\n",
    "        \n",
    "        # Prepare the result dictionary with dynamic context columns\n",
    "        result = {\n",
    "            \"Query\": query,\n",
    "            \"Ideal Answer\": ideal_answer,\n",
    "            \"AI Response\": ai_response,\n",
    "            \"Score\": score\n",
    "        }\n",
    "        # Add each context as its own column\n",
    "        for i, chunk in enumerate(top_chunks):\n",
    "            result[f\"Context {i + 1}\"] = chunk\n",
    "        \n",
    "        # Append the result to the list\n",
    "        results.append(result)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6662616729736328\n",
      "0.6569515228271484\n",
      "0.6584525108337402\n",
      "0.6584525108337402\n",
      "0.6584525108337402\n",
      "0.6584525108337402\n",
      "0.6584525108337402\n",
      "0.6662616729736328\n"
     ]
    }
   ],
   "source": [
    "for k in range(1, 9):\n",
    "    print(asyncio.run(process_validation_data(k=k))['Score'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
