{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from rank_bm25 import BM25Okapi\n",
    "import fitz\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\") # Fazer o embedding usando esse\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extracts text from a PDF file and prints the first `num_chars` characters.\n",
    "\n",
    "    Args:\n",
    "    pdf_path (str): Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    str: Extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    # Open the PDF file\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # Initialize an empty string to store the extracted text\n",
    "\n",
    "    # Iterate through each page in the PDF\n",
    "    for page_num in range(mypdf.page_count):\n",
    "        page = mypdf[page_num]  # Get the page\n",
    "        text = page.get_text(\"text\")  # Extract text from the page\n",
    "        all_text += text  # Append the extracted text to the all_text string\n",
    "\n",
    "    return all_text  # Return the extracted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to chunk\n",
    "        chunk_size (int): Size of each chunk in characters\n",
    "        chunk_overlap (int): Overlap between chunks in characters\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: List of chunks with text and metadata\n",
    "    \"\"\"\n",
    "    chunks = []  # Initialize an empty list to store chunks\n",
    "    \n",
    "    # Iterate over the text with the specified chunk size and overlap\n",
    "    for i in range(0, len(text), chunk_size - chunk_overlap):\n",
    "        chunk = text[i:i + chunk_size]  # Extract a chunk of the specified size\n",
    "        if chunk:  # Ensure we don't add empty chunks\n",
    "            chunk_data = {\n",
    "                \"text\": chunk,  # The chunk text\n",
    "                \"metadata\": {\n",
    "                    \"start_char\": i,  # Start character index of the chunk\n",
    "                    \"end_char\": i + len(chunk)  # End character index of the chunk\n",
    "                }\n",
    "            }\n",
    "            chunks.append(chunk_data)  # Add the chunk data to the list\n",
    "    \n",
    "    print(f\"Created {len(chunks)} text chunks\")  # Print the number of created chunks\n",
    "    return chunks  # Return the list of chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean text by removing extra whitespace and special characters.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text\n",
    "        \n",
    "    Returns:\n",
    "        str: Cleaned text\n",
    "    \"\"\"\n",
    "    # Replace multiple whitespace characters (including newlines and tabs) with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Fix common OCR issues by replacing tab and newline characters with a space\n",
    "    text = text.replace('\\\\t', ' ')\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    \n",
    "    # Remove any leading or trailing whitespace and ensure single spaces between words\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text):\n",
    "    \"\"\"\n",
    "    Create embeddings for the given text.\n",
    "    \n",
    "    Args:\n",
    "        texts (str or List[str]): Input text(s)\n",
    "        model (str): Embedding model name\n",
    "        \n",
    "    Returns:\n",
    "        List[List[float]]: Embedding vector(s)\n",
    "    \"\"\"\n",
    "    # Create embeddings for the current batch\n",
    "    response = embedder.encode(text)\n",
    "    return response  # Return the embeddings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVectorStore:\n",
    "    \"\"\"\n",
    "    A simple vector store implementation using NumPy.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vectors = []  # List to store embedding vectors\n",
    "        self.texts = []  # List to store text content\n",
    "        self.metadata = []  # List to store metadata\n",
    "    \n",
    "    def add_item(self, text, embedding, metadata=None):\n",
    "        \"\"\"\n",
    "        Add an item to the vector store.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The text content\n",
    "            embedding (List[float]): The embedding vector\n",
    "            metadata (Dict, optional): Additional metadata\n",
    "        \"\"\"\n",
    "        self.vectors.append(np.array(embedding))  # Append the embedding vector\n",
    "        self.texts.append(text)  # Append the text content\n",
    "        self.metadata.append(metadata or {})  # Append the metadata (or empty dict if None)\n",
    "    \n",
    "    def add_items(self, items, embeddings):\n",
    "        \"\"\"\n",
    "        Add multiple items to the vector store.\n",
    "        \n",
    "        Args:\n",
    "            items (List[Dict]): List of text items\n",
    "            embeddings (List[List[float]]): List of embedding vectors\n",
    "        \"\"\"\n",
    "        for i, (item, embedding) in enumerate(zip(items, embeddings)):\n",
    "            self.add_item(\n",
    "                text=item[\"text\"],  # Extract text from item\n",
    "                embedding=embedding,  # Use corresponding embedding\n",
    "                metadata={**item.get(\"metadata\", {}), \"index\": i}  # Merge item metadata with index\n",
    "            )\n",
    "    \n",
    "    def similarity_search_with_scores(self, query_embedding, k=5):\n",
    "        \"\"\"\n",
    "        Find the most similar items to a query embedding with similarity scores.\n",
    "        \n",
    "        Args:\n",
    "            query_embedding (List[float]): Query embedding vector\n",
    "            k (int): Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List[Tuple[Dict, float]]: Top k most similar items with scores\n",
    "        \"\"\"\n",
    "        if not self.vectors:\n",
    "            return []  # Return empty list if no vectors are stored\n",
    "        \n",
    "        # Convert query embedding to numpy array\n",
    "        query_vector = np.array(query_embedding)\n",
    "        \n",
    "        # Calculate similarities using cosine similarity\n",
    "        similarities = []\n",
    "        for i, vector in enumerate(self.vectors):\n",
    "            similarity = cosine_similarity([query_vector], [vector])[0][0]  # Compute cosine similarity\n",
    "            similarities.append((i, similarity))  # Append index and similarity score\n",
    "        \n",
    "        # Sort by similarity (descending)\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top k results with scores\n",
    "        results = []\n",
    "        for i in range(min(k, len(similarities))):\n",
    "            idx, score = similarities[i]\n",
    "            results.append({\n",
    "                \"text\": self.texts[idx],  # Retrieve text by index\n",
    "                \"metadata\": self.metadata[idx],  # Retrieve metadata by index\n",
    "                \"similarity\": float(score)  # Add similarity score\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def get_all_documents(self):\n",
    "        \"\"\"\n",
    "        Get all documents in the store.\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: All documents\n",
    "        \"\"\"\n",
    "        return [{\"text\": text, \"metadata\": meta} for text, meta in zip(self.texts, self.metadata)]  # Combine texts and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bm25_index(chunks):\n",
    "    \"\"\"\n",
    "    Create a BM25 index from the given chunks.\n",
    "    \n",
    "    Args:\n",
    "        chunks (List[Dict]): List of text chunks\n",
    "        \n",
    "    Returns:\n",
    "        BM25Okapi: A BM25 index\n",
    "    \"\"\"\n",
    "    # Extract text from each chunk\n",
    "    texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    \n",
    "    # Tokenize each document by splitting on whitespace\n",
    "    tokenized_docs = [text.split() for text in texts]\n",
    "    \n",
    "    # Create the BM25 index using the tokenized documents\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    # Print the number of documents in the BM25 index\n",
    "    print(f\"Created BM25 index with {len(texts)} documents\")\n",
    "    \n",
    "    return bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(bm25, chunks, query, k=5):\n",
    "    \"\"\"\n",
    "    Search the BM25 index with a query.\n",
    "    \n",
    "    Args:\n",
    "        bm25 (BM25Okapi): BM25 index\n",
    "        chunks (List[Dict]): List of text chunks\n",
    "        query (str): Query string\n",
    "        k (int): Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: Top k results with scores\n",
    "    \"\"\"\n",
    "    # Tokenize the query by splitting it into individual words\n",
    "    query_tokens = query.split()\n",
    "    \n",
    "    # Get BM25 scores for the query tokens against the indexed documents\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    \n",
    "    # Initialize an empty list to store results with their scores\n",
    "    results = []\n",
    "    \n",
    "    # Iterate over the scores and corresponding chunks\n",
    "    for i, score in enumerate(scores):\n",
    "        # Create a copy of the metadata to avoid modifying the original\n",
    "        metadata = chunks[i].get(\"metadata\", {}).copy()\n",
    "        # Add index to metadata\n",
    "        metadata[\"index\"] = i\n",
    "        \n",
    "        results.append({\n",
    "            \"text\": chunks[i][\"text\"],\n",
    "            \"metadata\": metadata,  # Add metadata with index\n",
    "            \"bm25_score\": float(score)\n",
    "        })\n",
    "    \n",
    "    # Sort the results by BM25 score in descending order\n",
    "    results.sort(key=lambda x: x[\"bm25_score\"], reverse=True)\n",
    "    \n",
    "    # Return the top k results\n",
    "    return results[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_retrieval(query, chunks, vector_store, bm25_index, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Perform fusion retrieval combining vector-based and BM25 search.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Query string\n",
    "        chunks (List[Dict]): Original text chunks\n",
    "        vector_store (SimpleVectorStore): Vector store\n",
    "        bm25_index (BM25Okapi): BM25 index\n",
    "        k (int): Number of results to return\n",
    "        alpha (float): Weight for vector scores (0-1), where 1-alpha is BM25 weight\n",
    "        \n",
    "    Returns:\n",
    "        List[Dict]: Top k results based on combined scores\n",
    "    \"\"\"\n",
    "    print(f\"Performing fusion retrieval for query: {query}\")\n",
    "    \n",
    "    # Define small epsilon to avoid division by zero\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    # Get vector search results\n",
    "    query_embedding = create_embeddings(query)  # Create embedding for the query\n",
    "    vector_results = vector_store.similarity_search_with_scores(query_embedding, k=len(chunks))  # Perform vector search\n",
    "    \n",
    "    # Get BM25 search results\n",
    "    bm25_results = bm25_search(bm25_index, chunks, query, k=len(chunks))  # Perform BM25 search\n",
    "    \n",
    "    # Create dictionaries to map document index to score\n",
    "    vector_scores_dict = {result[\"metadata\"][\"index\"]: result[\"similarity\"] for result in vector_results}\n",
    "    bm25_scores_dict = {result[\"metadata\"][\"index\"]: result[\"bm25_score\"] for result in bm25_results}\n",
    "    \n",
    "    # Ensure all documents have scores for both methods\n",
    "    all_docs = vector_store.get_all_documents()\n",
    "    combined_results = []\n",
    "    \n",
    "    for i, doc in enumerate(all_docs):\n",
    "        vector_score = vector_scores_dict.get(i, 0.0)  # Get vector score or 0 if not found\n",
    "        bm25_score = bm25_scores_dict.get(i, 0.0)  # Get BM25 score or 0 if not found\n",
    "        combined_results.append({\n",
    "            \"text\": doc[\"text\"],\n",
    "            \"metadata\": doc[\"metadata\"],\n",
    "            \"vector_score\": vector_score,\n",
    "            \"bm25_score\": bm25_score,\n",
    "            \"index\": i\n",
    "        })\n",
    "    \n",
    "    # Extract scores as arrays\n",
    "    vector_scores = np.array([doc[\"vector_score\"] for doc in combined_results])\n",
    "    bm25_scores = np.array([doc[\"bm25_score\"] for doc in combined_results])\n",
    "    \n",
    "    print(f\"vector scores: {vector_scores}\")\n",
    "    print(f\"Alpha: {alpha}\")\n",
    "    print(f\"1 - Alpha: {1 - alpha}\")\n",
    "    print(f\"bm25 scores: {bm25_scores}\")\n",
    "\n",
    "    # Normalize scores\n",
    "    norm_vector_scores = (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores) + epsilon)\n",
    "    norm_bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores) + epsilon)\n",
    "    \n",
    "    # Compute combined scores\n",
    "    combined_scores = alpha * norm_vector_scores + (1 - alpha) * norm_bm25_scores\n",
    "    \n",
    "    # Add combined scores to results\n",
    "    for i, score in enumerate(combined_scores):\n",
    "        combined_results[i][\"combined_score\"] = float(score)\n",
    "    \n",
    "    # Sort by combined score (descending)\n",
    "    combined_results.sort(key=lambda x: x[\"combined_score\"], reverse=True)\n",
    "    \n",
    "    # Return top k results\n",
    "    top_results = combined_results[:k]\n",
    "    \n",
    "    print(f\"Retrieved {len(top_results)} documents with fusion retrieval\")\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(pdf_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Process a document for fusion retrieval.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        chunk_size (int): Size of each chunk in characters\n",
    "        chunk_overlap (int): Overlap between chunks in characters\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[Dict], SimpleVectorStore, BM25Okapi]: Chunks, vector store, and BM25 index\n",
    "    \"\"\"\n",
    "    # Extract text from the PDF file\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Clean the extracted text to remove extra whitespace and special characters\n",
    "    cleaned_text = clean_text(text)\n",
    "    \n",
    "    # Split the cleaned text into overlapping chunks\n",
    "    chunks = chunk_text(cleaned_text, chunk_size, chunk_overlap)\n",
    "    \n",
    "    # Extract the text content from each chunk for embedding creation\n",
    "    chunk_texts = [chunk[\"text\"] for chunk in chunks]\n",
    "    print(\"Creating embeddings for chunks...\")\n",
    "    \n",
    "    # Create embeddings for the chunk texts\n",
    "    embeddings = create_embeddings(chunk_texts)\n",
    "    \n",
    "    # Initialize the vector store\n",
    "    vector_store = SimpleVectorStore()\n",
    "    \n",
    "    # Add the chunks and their embeddings to the vector store\n",
    "    vector_store.add_items(chunks, embeddings)\n",
    "    print(f\"Added {len(chunks)} items to vector store\")\n",
    "    \n",
    "    # Create a BM25 index from the chunks\n",
    "    bm25_index = create_bm25_index(chunks)\n",
    "    \n",
    "    # Return the chunks, vector store, and BM25 index\n",
    "    return chunks, vector_store, bm25_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, context):\n",
    "    \"\"\"\n",
    "    Generate a response based on the query and context.\n",
    "    \n",
    "    Args:\n",
    "        query (str): User query\n",
    "        context (str): Context from retrieved documents\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated response\n",
    "    \"\"\"\n",
    "    # Define the system prompt to guide the AI assistant\n",
    "    system_prompt = \"\"\"You are a helpful AI assistant. Answer the user's question based on the provided context. \n",
    "    If the context doesn't contain relevant information to answer the question fully, acknowledge this limitation.\"\"\"\n",
    "\n",
    "    # Format the user prompt with the context and query\n",
    "    user_prompt = f\"\"\"Context:\n",
    "    {context}\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    Please answer the question based on the provided context.\"\"\"\n",
    "\n",
    "    # Generate the response using the OpenAI API\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",  # Specify the model to use\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},  # System message to guide the assistant\n",
    "            {\"role\": \"user\", \"content\": user_prompt}  # User message with context and query\n",
    "        ],\n",
    "        temperature=0.1  # Set the temperature for response generation\n",
    "    )\n",
    "    \n",
    "    # Return the generated response\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_with_fusion_rag(query, chunks, vector_store, bm25_index, k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Answer a query using fusion RAG.\n",
    "    \n",
    "    Args:\n",
    "        query (str): User query\n",
    "        chunks (List[Dict]): Text chunks\n",
    "        vector_store (SimpleVectorStore): Vector store\n",
    "        bm25_index (BM25Okapi): BM25 index\n",
    "        k (int): Number of documents to retrieve\n",
    "        alpha (float): Weight for vector scores\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Query results including retrieved documents and response\n",
    "    \"\"\"\n",
    "    # Retrieve documents using fusion retrieval method\n",
    "    retrieved_docs = fusion_retrieval(query, chunks, vector_store, bm25_index, k=k, alpha=alpha)\n",
    "    \n",
    "    # Format the context from the retrieved documents by joining their text with separators\n",
    "    context = \"\\n\\n---\\n\\n\".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "    \n",
    "    # Generate a response based on the query and the formatted context\n",
    "    response = generate_response(query, context)\n",
    "    \n",
    "    # Return the query, retrieved documents, and the generated response\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": retrieved_docs,\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 42 text chunks\n",
      "Creating embeddings for chunks...\n",
      "Added 42 items to vector store\n",
      "Created BM25 index with 42 documents\n"
     ]
    }
   ],
   "source": [
    "chunks, vector_store, bm25_index = process_document(\"AI_Information.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created BM25 index with 42 documents\n",
      "Performing fusion retrieval for query: What is artificial intelligence?\n",
      "vector scores: [0.7433635  0.54601061 0.43958056 0.42608011 0.36637625 0.48235208\n",
      " 0.53574812 0.56143618 0.40263274 0.40873906 0.41222674 0.37130743\n",
      " 0.40511107 0.49916551 0.42931235 0.38744962 0.38743073 0.36604521\n",
      " 0.44279024 0.48129061 0.46574518 0.42452952 0.43626469 0.4350239\n",
      " 0.37664813 0.41399723 0.40133178 0.4530105  0.3458541  0.46268743\n",
      " 0.37514341 0.43351191 0.37324965 0.43635452 0.42823768 0.39975524\n",
      " 0.37688848 0.41114178 0.37470832 0.39046559 0.49881044 0.39450854]\n",
      "Alpha: 0.5\n",
      "1 - Alpha: 0.5\n",
      "bm25 scores: [3.66658871 1.13984143 0.97593044 3.67773839 0.67955219 1.33035843\n",
      " 1.17446639 1.17446639 1.14194556 1.15689489 0.96905085 1.14194556\n",
      " 0.         0.         0.69559887 1.15689489 0.73007846 0.70032378\n",
      " 0.9645181  1.13774503 0.99716803 0.         0.70511332 0.\n",
      " 0.71737875 0.         0.68633778 0.         0.70511332 1.13984143\n",
      " 0.97362642 1.14194556 1.01683717 0.         1.16561442 0.67510252\n",
      " 0.69795333 1.14830485 0.98998687 0.         0.         0.        ]\n",
      "Retrieved 5 documents with fusion retrieval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is artificial intelligence?',\n",
       " 'retrieved_documents': [{'text': 'Understanding Artificial Intelligence Chapter 1: Introduction to Artificial Intelligence Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings. The term is frequently applied to the project of developing systems endowed with the intellectual processes characteristic of humans, such as the ability to reason, discover meaning, generalize, or learn from past experience. Over the past few decades, advancements in computing power and data availability have significantly accelerated the development and deployment of AI. Historical Context The idea of artificial intelligence has existed for centuries, often depicted in myths and fiction. However, the formal field of AI research began in the mid-20th century. The Dartmouth Workshop in 1956 is widely considered the birthplace of AI. Early AI research focused on problem-solving and symbolic methods. The 1980s saw a rise in expert systems,',\n",
       "   'metadata': {'start_char': 0, 'end_char': 1000, 'index': 0},\n",
       "   'vector_score': 0.7433634996414185,\n",
       "   'bm25_score': 3.666588713658085,\n",
       "   'index': 0,\n",
       "   'combined_score': 0.9984841532361473},\n",
       "  {'text': 'the algorithm must discover patterns and structures in the data without explicit guidance. Common techniques include clustering (grouping similar data points) and dimensionality reduction (reducing the number of variables while preserving important information). Reinforcement Learning Reinforcement learning involves training an agent to make decisions in an environment to maximize a reward. The agent learns through trial and error, receiving feedback in the form of rewards or penalties. This approach is used in game playing, robotics, and resource management. Deep Learning Deep learning is a subfield of machine learning that uses artificial neural networks with multiple layers (deep neural networks) to analyze data. These networks are inspired by the structure and function of the human brain. Deep learning has achieved significant breakthroughs in areas such as image recognition, natural language processing, and speech recognition. Convolutional Neural Networks (CNNs) CNNs are a type o',\n",
       "   'metadata': {'start_char': 2400, 'end_char': 3400, 'index': 3},\n",
       "   'vector_score': 0.4260801076889038,\n",
       "   'bm25_score': 3.6777383868328255,\n",
       "   'index': 3,\n",
       "   'combined_score': 0.6009108235132625},\n",
       "  {'text': 'yze customer data to predict demand, personalize offers, and improve the shopping experience. Manufacturing AI is used in manufacturing for predictive maintenance, quality control, process optimization, and robotics. AI-powered systems can monitor equipment, detect anomalies, and automate tasks, leading to increased efficiency and reduced costs. Education AI is enhancing education through personalized learning platforms, automated grading systems, and virtual tutors. AI-powered tools can adapt to individual student needs, provide feedback, and create customized learning experiences. Entertainment The entertainment industry uses AI for content recommendation, game development, and virtual reality experiences. AI algorithms analyze user preferences to suggest movies, music, and games, enhancing user engagement. Cybersecurity AI is used in cybersecurity to detect and respond to threats, analyze network traffic, and identify vulnerabilities. AI-powered systems can automate security tasks, ',\n",
       "   'metadata': {'start_char': 5600, 'end_char': 6600, 'index': 7},\n",
       "   'vector_score': 0.5614361763000488,\n",
       "   'bm25_score': 1.174466388331987,\n",
       "   'index': 7,\n",
       "   'combined_score': 0.43083836867560726},\n",
       "  {'text': 'e mid-20th century. The Dartmouth Workshop in 1956 is widely considered the birthplace of AI. Early AI research focused on problem-solving and symbolic methods. The 1980s saw a rise in expert systems, while the 1990s and 2000s brought advancements in machine learning and neural networks. Recent breakthroughs in deep learning have revolutionized the field. Modern Observations Modern AI systems are increasingly prevalent in everyday life. From virtual assistants like Siri and Alexa to recommendation algorithms on streaming services and social media, AI is impacting how we live, work, and interact. The development of self-driving cars, advanced medical diagnostics, and sophisticated financial modeling tools demonstrates the broad and growing applications of AI. Concerns about ethical implications, bias, and job displacement are also increasingly prominent. Chapter 2: Core Concepts of Artificial Intelligence Machine Learning Machine learning (ML) is a subset of AI that focuses on enabling ',\n",
       "   'metadata': {'start_char': 800, 'end_char': 1800, 'index': 1},\n",
       "   'vector_score': 0.5460106134414673,\n",
       "   'bm25_score': 1.139841425053971,\n",
       "   'index': 1,\n",
       "   'combined_score': 0.40672823238617073},\n",
       "  {'text': ' medicine, and robotic surgery. AI-powered tools can analyze medical images, predict patient outcomes, and assist in treatment planning. Finance In finance, AI is used for fraud detection, algorithmic trading, risk management, and customer service. AI algorithms can analyze large datasets to identify patterns, predict market trends, and automate financial processes. Transportation AI is revolutionizing transportation with the development of self-driving cars, traffic optimization systems, and logistics management. Autonomous vehicles use AI to perceive their surroundings, make driving decisions, and navigate safely. Retail The retail industry uses AI for personalized recommendations, inventory management, customer service chatbots, and supply chain optimization. AI-powered systems can analyze customer data to predict demand, personalize offers, and improve the shopping experience. Manufacturing AI is used in manufacturing for predictive maintenance, quality control, process optimizatio',\n",
       "   'metadata': {'start_char': 4800, 'end_char': 5800, 'index': 6},\n",
       "   'vector_score': 0.5357481241226196,\n",
       "   'bm25_score': 1.174466388331987,\n",
       "   'index': 6,\n",
       "   'combined_score': 0.39852711794195195}],\n",
       " 'response': 'Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot to perform tasks commonly associated with intelligent beings. This includes processes such as reasoning, discovering meaning, generalizing, and learning from past experience. AI encompasses various subfields such as machine learning, deep learning, reinforcement learning, and the use of algorithms to analyze data and make decisions. AI has a wide range of applications across industries, including healthcare, finance, transportation, retail, entertainment, cybersecurity, and education. Additionally, the development of AI has raised concerns about ethical implications, bias, and job displacement.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_with_fusion_rag(\n",
    "    query=\"What is artificial intelligence?\",\n",
    "    chunks=chunks,\n",
    "    vector_store=vector_store,\n",
    "    bm25_index=create_bm25_index(chunks)\n",
    ")  # Example query to test the fusion RAG system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
